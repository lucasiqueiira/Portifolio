{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this project, I will build an image classification model using data from the dataset [Food101](https://www.tensorflow.org/datasets/catalog/food101).\n",
    "### In this project I will use transfer learning, the chosen pre-trained model is [EfficientNet V2 B0](https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet_v2/EfficientNetV2B0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWp-Tphpz0Y5"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "W77Bf-e9P6kB",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 11:53:47.164702: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-12 11:53:47.740113: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/lucas/miniconda3/envs/tf/lib/\n",
      "2023-02-12 11:53:47.740166: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/lucas/miniconda3/envs/tf/lib/\n",
      "2023-02-12 11:53:47.740172: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HR1Tu5SZZ1RL",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.11.0\n",
      "tensorflow_datasets: 4.8.2\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensorflow: {tf.__version__}\")\n",
    "print(f\"tensorflow_datasets: {tfds.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwwCjRbsP6mz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "(train_data, test_data), ds_info = tfds.load(name=\"food101\", # target dataset to get from TFDS\n",
    "                                             split=[\"train\", \"validation\"], # what splits of data should we get? note: not all datasets have train, valid, test\n",
    "                                             shuffle_files=True, # shuffle files on download?\n",
    "                                             as_supervised=True, # download data in tuple format (sample, label), e.g. (image, label)\n",
    "                                             with_info=True) # include dataset metadata? if so, tfds.load() returns tuple (data, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple_pie',\n",
       " 'baby_back_ribs',\n",
       " 'baklava',\n",
       " 'beef_carpaccio',\n",
       " 'beef_tartare',\n",
       " 'beet_salad',\n",
       " 'beignets',\n",
       " 'bibimbap',\n",
       " 'bread_pudding',\n",
       " 'breakfast_burrito']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = ds_info.features[\"label\"].names\n",
    "class_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffv5n57qdNW1"
   },
   "outputs": [],
   "source": [
    "# Seria bom plotar uma imagem de exemplo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To pass the images to our network, we need them to be in (224,224,3) format, we also need to convert them to float.32 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XJnugu-JP6vH"
   },
   "outputs": [],
   "source": [
    "# Function for preprocessing images\n",
    "def preprocess_img(image, label, img_shape=224):\n",
    "    \"\"\"\n",
    "    Converts image datatype from 'uint8' -> 'float32' and reshapes image to\n",
    "    [img_shape, img_shape, color_channels]\n",
    "    \"\"\"\n",
    "    image = tf.image.resize(image, [img_shape, img_shape]) # reshape to img_shape\n",
    "    return tf.cast(image, tf.float32), label # return (float32_image, label) tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "L_k1jDvZdNb_"
   },
   "outputs": [],
   "source": [
    "# Map preprocessing function to training data (and paralellize)\n",
    "train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Shuffle train_data and turn it into batches and prefetch it (load it faster)\n",
    "train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Map prepreprocessing function to test data\n",
    "test_data = test_data.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Turn test data into batches (don't need to shuffle)\n",
    "test_data = test_data.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-3_LG-yudNet"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n",
       " <PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qEqjUyHkdNiF"
   },
   "outputs": [],
   "source": [
    "# Create ModelCheckpoint callback to save model's progress\n",
    "checkpoint_path = \"model_checkpoints/cp.ckpt\" # saving weights requires \".ckpt\" extension\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                      monitor=\"val_accuracy\", # save the model weights with best validation accuracy\n",
    "                                                      save_best_only=True, # only save the best weights\n",
    "                                                      save_weights_only=True, # only save model weights (not whole model)\n",
    "                                                      verbose=0) # don't print out whether or not model is being saved "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUmDlhOTdNkV"
   },
   "source": [
    "### MIXED PRECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Mixed precision is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jgTN0rEWdNm8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3060, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 18:56:42.433899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3060, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "# Turn on mixed precision training\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(policy=\"mixed_float16\") # set global policy to mixed precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4FDlZOs_dNsk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Policy \"mixed_float16\">"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_precision.global_policy() # should output \"mixed_float16\" (if your GPU is compatible with mixed precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's create our model, as said before, we will use EfficientNetV2B0, we don't need to rescale our images before passing to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YzzmLKuVdNvU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
      "24274472/24274472 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# Create base model\n",
    "input_shape = (224, 224, 3)\n",
    "base_model = tf.keras.applications.EfficientNetV2B0(include_top=False)\n",
    "base_model.trainable = False # freeze base model layers\n",
    "\n",
    "# Create Functional model \n",
    "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "x = base_model(inputs, training=False) # set base_model to inference mode only\n",
    "x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
    "x = layers.Dense(len(class_names))(x) # want one output neuron per class \n",
    "# Separate activation of output layer so we can output float32 activations\n",
    "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x) \n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", # Use sparse_categorical_crossentropy when labels are *not* one-hot\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zEf3-r3cdNyU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Function  (None, None, None, 1280)  5919312  \n",
      " al)                                                             \n",
      "                                                                 \n",
      " pooling_layer (GlobalAverag  (None, 1280)             0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 101)               129381    \n",
      "                                                                 \n",
      " softmax_float32 (Activation  (None, 101)              0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,048,693\n",
      "Trainable params: 129,381\n",
      "Non-trainable params: 5,919,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check out our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "s14aYe0LdN1M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 18:57:09.329404: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-02-06 18:57:11.045701: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-06 18:57:12.992882: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f01a5fd8090 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-06 18:57:12.992926: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-02-06 18:57:13.030156: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2368 [..............................] - ETA: 6:46:37 - loss: 4.7271 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 18:57:13.340702: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-06 18:57:13.372748: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2368/2368 [==============================] - 117s 45ms/step - loss: 1.7458 - accuracy: 0.5782 - val_loss: 1.1416 - val_accuracy: 0.7013\n",
      "Epoch 2/3\n",
      "2368/2368 [==============================] - 105s 44ms/step - loss: 1.2112 - accuracy: 0.6866 - val_loss: 1.0278 - val_accuracy: 0.7251\n",
      "Epoch 3/3\n",
      "2368/2368 [==============================] - 110s 46ms/step - loss: 1.0646 - accuracy: 0.7211 - val_loss: 1.0008 - val_accuracy: 0.7307\n"
     ]
    }
   ],
   "source": [
    "# Turn off all warnings except for errors\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Fit the model with callbacks\n",
    "history_101_food_classes_feature_extract = model.fit(train_data, \n",
    "                                                     epochs=3,\n",
    "                                                     steps_per_epoch=len(train_data),\n",
    "                                                     validation_data=test_data,\n",
    "                                                     validation_steps=int(0.15 * len(test_data)),\n",
    "                                                     callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "huJNvtoWdN4E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 33s 41ms/step - loss: 0.9987 - accuracy: 0.7299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9986572265625, 0.7299010157585144]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model (unsaved version) on whole test dataset\n",
    "results_feature_extract_model = model.evaluate(test_data)\n",
    "results_feature_extract_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VR5rOG-Bf8DF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 92). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "# Save model locally\n",
    "save_dir = \"07_efficientnetb0_feature_extract_model_mixed_precision\"\n",
    "model.save(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "UmYfIVe6f8Fo"
   },
   "outputs": [],
   "source": [
    "# Load model previously saved above\n",
    "loaded_saved_model = tf.keras.models.load_model(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "321hrKY2dOAM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
